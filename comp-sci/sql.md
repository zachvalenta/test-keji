# TODO

## å‚è€ƒ

ğŸ” https://dba.stackexchange.com
ğŸ“š
* Beaulieu learning sql
* Conery curious moon
* Evans star https://sql-playground.wizardzines.com/
* Faroult art of sql
* Karwin sql antipatterns https://pragprog.com/cms/errata/bksqla-errata/
* Molinaro sql cookbook

## current

## queue

rf
* port Beaulieu to paper copy
* grouping ğŸ“™ Evans 8, Beaulieu ch. 8

interviewing
* https://github.com/alexeygrigorev/data-science-interviews/blob/master/technical.md
* https://leetcode.com/problemset/database/
* https://www.hackerrank.com/domains/sql
* https://www.youtube.com/channel/UCW8Ews7tdKKkBT6GdtQaXvQ/videos

## done

* _21_: semantics (migrations, tables), `query-sandbox`, litecli config
* _20_: start `sjk`, Flask-SQLAlchemy (pagination, 1-m w/ backrefs, Marshmallow for nested serializers), visidata
* _19_: ğŸ“™ Beaulieu chapters 1-5 and 10; Flask-SQLAlchemy (FK, through table, raw SQL) SQLite (FK support) SQLAlchemy (core, parameterized queries)
* _18_: Flyway for Dark Canary, modeling course
* _17_: subqueries for Case

# DDL

ğŸ”— http://eradman.com/posts/schema-definition.html

semantics
* _domain_: thing you're trying to model https://calpaterson.com/non-relational-beartraps.html
* _schema_: model of thing https://calpaterson.com/non-relational-beartraps.html
* general usage: table names + column name/type https://news.ycombinator.com/item?id=22723277
* Postgres usage: container for obj such as table or view https://news.ycombinator.com/item?id=22721914

* commands
```sql
-- DB/TABLE
CREATE DATABASE <db>;  -- `sqlite3 local.db`
CREATE TABLE test_table ();
DROP TABLE <table>;
DROP DATABASE <db>;

-- ATTR
ALTER TABLE <table> ADD <col> <type>;  -- add
ALTER TABLE <table> ALTER COLUMN <col> INT NULL  -- update type
UPDATE <table> set <col>=concat('prependThis_', <col>)  -- update name
ALTER TABLE <table> DROP COLUMN <col>; -- rm
DESCRIBE mytable; -- list constraints/indexes
SHOW CREATE TABLE <tab>; -- MySQL version https://serverfault.com/q/231952 https://stackoverflow.com/a/201678
PRAGMA index_list('<tab>') -- SQLite version https://stackoverflow.com/a/49311235
```

## keys

primary key (PK) ğŸ—„ indexing `connolly.pdf`
* _candidate key_: key(s) that could serve as PK https://stackoverflow.com/a/12813385 ğŸ“™ Winand 1.5
* _primary key_: attr w/ unique constraint that serves as ID of record
* _composite key_: n keys unique together used as PK
* slower than surrogate https://news.ycombinator.com/item?id=2786238
* https://github.com/aswinkarthik/csvdiff
* https://sirupsen.com/napkin/problem-5
* _compound key_: composite key + all keys also FK https://en.wikipedia.org/wiki/Composite_key
* e.g. join table https://www.youtube.com/watch?v=vsGDtnBCwgg
* sometimes used interchangeably w/ 'composite' https://dba.stackexchange.com/a/3137/201798 https://www.youtube.com/watch?v=lnfrcHdE_HI 1:40
```sql

```
* _natural key_: attr that goes together with other attr in table (vs. surrogate key)
* _surrogate key_: unrelated to table attr https://stackoverflow.com/a/36773462
* typically autogenerated but doesn't necessarily have to be ğŸ“™ Beaulieu 2.31
```sql

```
* _sequence_: Karwin chapter 4, Beaulieu 2.31 https://stackoverflow.com/a/1649128
* don't expose via API, use uuid https://0of1.com/blog/posts/django-staples/
* autoincrementing https://retool.com/blog/how-to-work-with-auto-increment-in-sql-query/ aka identity column https://www.sqltutorial.org/sql-identity/
```sql

```

foreign key (FK)
* _foreign key_: constraint enforcing reference to another table's PK
```sql
foreign key (band) references bands (band_id)
```
* aka referential integrity aka prevent garbage in garbage out https://www.postgresql.org/docs/8.3/tutorial-fk.html
* _parent_: table to which FK refers https://sqlite.org/foreignkeys.html#fk_basics
* _child_: table w/ FK ğŸ“™ Beaulieu 2.30-36, 5.82
* can be self-referencing? ğŸ“™ Beaulieu 5.93
* find FK referencing table ` SELECT * FROM information_schema.TABLE_CONSTRAINTS WHERE CONSTRAINT_SCHEMA='tableName' AND CONSTRAINT_TYPE='FOREIGN KEY'`
* bad when it comes to sharing and migrations? https://github.com/github/gh-ost/issues/331#issuecomment-266027731
* https://www.semicolonandsons.com/episode/foreign-keys-and-uniqueness-constraints

## migrations

ğŸ—„
* `system.md` deployment
* `lang/python/django/migrations-sandbox`

data migrations
* _data migration_: DML; change data itself
* _fixture_: data migration using serialization
* _factory_: data migration using ORM obj https://github.com/FactoryBoy/factory_boy/
* backsies https://news.ycombinator.com/item?id=30788768
* dry run https://adamj.eu/tech/2022/10/13/dry-run-mode-for-data-imports-in-django/

schema migrations
* _schema_: DDL; change schema (alongside related change in src) https://en.wikipedia.org/wiki/Schema_migration
* no needs to manually alter tables https://realpython.com/django-migrations-a-primer/#ensuring-model-definitions-and-the-database-schema-in-sync
* can be generated from model changes https://realpython.com/django-migrations-a-primer/#avoiding-repetition
* version controllable https://realpython.com/django-migrations-a-primer/#tracking-database-schema-change-in-version-control
* aids deployment (easy rollback to previous) ğŸ—„ `system.md` deployment
* don't run on app start https://pythonspeed.com/articles/schema-migrations-server-startup/
* BYO https://news.ycombinator.com/item?id=24577239

---

https://github.com/amacneil/dbmate#alternatives
* SQLite https://news.ycombinator.com/item?id=31249823
* https://github.com/fabianlindfors/reshape
* linear migrations https://github.com/adamchainz/django-linear-migrations?utm_campaign=Django%2BNewsletter&utm_medium=email&utm_source=Django_Newsletter_89

schema migrations - scenarios
* https://www.caktusgroup.com/blog/2021/05/25/django-migrations-and-deployment
* _rollback_: https://about.gitlab.com/blog/2020/09/16/year-of-kubernetes/
> We learned in the process of moving from VMs to Kubernetes that it was extremely beneficial for us to have an easy way to move traffic between the old and new infrastructure, and to keep legacy infrastructure available for rollback in the first few days after the migration.
> And if what you care about is downtime, your first thought shouldnâ€™t be "how do I reduce deployment downtime from 1 second to 1ms", it should be "how can I ensure database schema changes donâ€™t prevent rollback if I screw something up." - https://pythonspeed.com/articles/dont-need-kubernetes/
> Applying a schema migration to a production database is always a risk...the migration process needs a high level of discipline, thorough testing and a sound backup strategy. https://en.wikipedia.org/wiki/Template:Database https://en.wikipedia.org/wiki/Schema_migration
* _rm attr_: instead of dropping can just hide from interface https://www.reddit.com/r/django/comments/47k7kl/how_do_i_make_a_migration_without_dropping_columns/
* _add attr_: nullable or add default for old records; if nullable, need to update API if you don't want to return those null values; defaults not recommended [Kleppmann 4.130]
> in Django, if you add default at model level, the old records are still null, yes? so you'd still have to update API to handle those, as you would if you'd made the attr nullable
> in Django, how do people handle the one-off default for existing data? before you have prod data, foo values seem fine, but curious to hear a discussion on this topic
```diff
class Foo(models.Model):
    bar = models.CharField(max_length=255)
+   baz = models.CharField(max_length=255, null=True)
```
```sh
+----+---------+----------+
| id | bar     | baz      |
+----+--------------------+
| 1  | bar val | <null>   |
| 2  | bar val | baz val  |
+----+--------------------+
```

* _sink_: https://www.tarynpivots.com/post/migrating-40tb-sql-server-database/ https://github.blog/2020-02-14-automating-mysql-schema-migrations-with-github-actions-and-more/

compatibility https://thorben-janssen.com/update-database-schema-without-downtime/
* _backward compatibility_: new code can handle old data [Kleppmann 4.112]
> is the old data really old?
> e.g. add attr, previous records don't have value for attr but have attr itself
> client/server can just massage data to handle null values

* _forward compatibility_: old code can handle new data; typically harder to do [Kleppmann 4.112] typically old code doesn't touch new fields [ibid 4.129]
> how would this happen unless you logged in 

Flyway https://flywaydb.org/documentation/ https://github.com/zachvalenta/flyway-tutorial
* how it works
> It's semi automatic because it does not find out what has actually changed in your model. You need to write actual SQL scripts that have versions. It will create a separate table to keep track what version you have in your data base and that execute the script automatically up to the point where the latest version is reached.
* _alternatives_: Liquibase https://return.co.de/blog/articles/java-development-fast/ https://github.com/amacneil/dbmate
* _CLI_: db you're connected to, what migrations need to be run; selects subset of `flyway_schema_history`; can change name of `flyway_schema_history` in `flyway.conf > flway.table`
* _config_: `flyway.conf` unless overriden from CLI
* _directory structure_: `flyway` (CLI; bash script gathers input and then runs Flyway, itself a Java app) `lib` (actual Flyway application) `sql` (ur scripts here)
* _migration script location_: `classpath:db/migration` (in src) `libexec/sql` (in local Flyway install)
* _naming conventions_: whole numbers or timestamps, pad your numbers, don't alter in `flyway.conf`
* _types_: versioned (default) repeatable https://flywaydb.org/getstarted/repeatable undo https://flywaydb.org/getstarted/undo just make a new migration file (vs. using `flyway repair`) ['How to Correct a Mistake in a Migration']
* _versions_: looks at `version` table; version numbers https://flywaydb.org/documentation/migrations#naming
* _with Java_: if you drop tables and rerun app, run `mvn clean install` before rerun (think something cached between runs (in `target`?) indicating that scripts have already been run --> this is weird bc Flyway should look to version table in the database for that)

## normalization

ğŸ”— https://en.wikipedia.org/wiki/Database_normalization#Normal_forms

forms
* _1NF_: 1 value for each attr
* aka atomic ğŸ“™ Takahashi [58] Winand [6]
```sql
-- pre-1NF: n values for each record
insert into danzi(item) values ('quesidilla, churro');

-- 1NF: 1 value for each record
insert into danzi(item) values ('quesidilla');
insert into danzi(item) values ('churro');
```

* _2NF_: non-PK must be related to PK ğŸ“™ Conery imposter 316 Takahashi 3.63 https://stackoverflow.com/a/724032
* symptom is redundancy (value repeats across records w/out reference to FK) and therefore anomaly (value could be mispelled) ğŸ“™ Karwin 289
```sql
-- TITLE dependent on COURSE_ID but unrelated to SEMESTER_ID
CourseID | SemesterID | #Places  | Title        |
------------------------------------------------|
IT101    |   2009-1   | 100      | Programming  |
IT101    |   2009-2   | 100      | Programming  |
IT102    |   2009-1   | 200      | Databases    |
IT102    |   2010-1   | 150      | Databases    |
IT103    |   2009-2   | 120      | Web Design   |

```

* _3NF_: don't get difference from 2NF ğŸ“™ Conery imposter 318 Karwin 291
* the generally accepted level of normalization ğŸ“™ Winand 1.4
* https://stackoverflow.com/a/724013/6813490 https://www.mikealche.com/software-development/a-humble-guide-to-database-schema-design
```sql

```

normalization
* _normalization_: process of extracting entities from other entities
* _form_: step in normalization
* avoids redundancy (no `author` in `book` bc you'd repeat Jane Austen for each novel)
* saves space (no dupes) ğŸ“™ Kleppmann 2.33
* how to normalize: one big mess and decompose from there, think of example queries
* _5NF (Boyce-Codd)_: when you're going too far ğŸ“™ Winand 1.5

denormalization
* when speed more of a concern ğŸ“™ Conery imposter 320 Kleppmann 491
* aka unnormalized ğŸ“™ Manga 3.62
* _locality_: proximity of data relevant to an entity ğŸ“™ Kleppmann 2.32 ğŸ—„ `db.md` document
* _denormalized query engine_: subset of data for search https://speakerdeck.com/simon/the-denormalized-query-engine-design-pattern https://simonwillison.net/2020/Dec/19/dogsheep-beta/

## relations

ğŸ” https://drawsql.app/templates
ğŸ“™ Kent data/reality https://www.amazon.com/Data-Reality-Perspective-Perceiving-Information/dp/1935504215

* _relationship_: what ties tables together https://twobithistory.org/2017/12/29/codd-relational-model.html
* _relational model_: Codd ğŸ“™ Kent data/reality [155]
* _embeded_: NoSQL https://www.mongodb.com/docs/manual/core/data-model-design/
* importance
> Data models are perhaps the most important part of developing software, because they have such a profound effect: not only on how the software is written, but also how we think about the problem that we are solving. ğŸ“™ Kleppmann [31]
> This is one reason it's so important to model your domain correctly: if, for example, you make something a property of A when it should be a property of B, the penalty is often that operations that formerly required checking all the As or all the Bs now require checking all the As and all the Bs. https://www.natemeyvis.com/writing/on-quadratic-complexity/

1-1
* = sole ownership
* impl: attr, separate table https://support.airtable.com/hc/en-us/articles/218734758#onetoone
* example: person-SSN, country-capital https://stackoverflow.com/a/15037461

1-M
* = ownership
```sql
CREATE TABLE team(
    team_id INTEGER PRIMARY KEY,
);

CREATE TABLE player(
    player_id INTEGER PRIMARY KEY,
    team_id INTEGER,
    FOREIGN KEY (team_id) REFERENCES team(team_id)
);
```

M-M
* = collaboration
* aka join table, junction table https://stackoverflow.com/a/3419868
```sql
CREATE TABLE band(
    band_id INTEGER PRIMARY KEY,
);

CREATE TABLE musician(
    musician_id INTEGER PRIMARY KEY,
);

CREATE TABLE band_musician(
    bm_id INTEGER PRIMARY KEY,
    band INTEGER,
    musician INTEGER,
    FOREIGN KEY (band) REFERENCES band(band_id)
    FOREIGN KEY (musician) REFERENCES band(musician_id)
);
```

## typing

ğŸ“œ https://www.postgresql.org/docs/current/datatype.html
ğŸ—„ `db.md` SQLite/design
ğŸ“™ Beaulieu chapter 7

constraints / data integrity ğŸ“™ Beaulieu chapter 13
* _constraint_: rule for attr type/value e.g. `not null`, `foreign key`, `check` (range of acceptable values) [Beaulieu 2.28] PK and FK are types of constraints 
```sql
-- ğŸ“ port definitions to SQL
```
* _not null_: https://www.semicolonandsons.com/episode/data-integrity-null-constraint-check-constraint
* interpolation https://hakibenita.com/sql-for-data-analysis#interpolation
* _unique_: prevents dupes values in column https://stackoverflow.com/a/21049722/6813490 https://www.semicolonandsons.com/episode/foreign-keys-and-uniqueness-constraints
* _default_: value that will be inserted in the absence of an explicit value in an insert / update statement https://stackoverflow.com/a/11862246/6813490
```sql
CREATE TABLE test_table (
    foo default 'this is the default value', -- https://www.youtube.com/watch?v=lnfrcHdE_HI 3:15
```
* _check_: value for attr must satisfy boolean expression https://www.semicolonandsons.com/episode/data-integrity-null-constraint-check-constraint
```sql
-- https://www.postgresql.org/docs/12/ddl-constraints.html#DDL-CONSTRAINTS-CHECK-CONSTRAINTS
CREATE TABLE products (
    product_no integer,
    name text,
    price numeric CHECK (price > 0)
);
```

null
* _null_: absence of a value e.g. `termination_date` for newly hired employee
* wat
```sql
null != null  -- true ğŸ“™ Beaulieu 4.76-7
select (0 is not null) and ('' is not null)  -- true
```

types
* _blob_: `text` in Postgres, `longtext` in MySQL
* integer
> The type integer is the common choice, as it offers the best balance between range, storage size, and performance. The smallint type is generally only used if disk space is at a premium. The bigint type is designed to be used when the range of the integer type is insufficient. https://www.postgresql.org/docs/current/datatype-numeric.html#DATATYPE-INT
* _boolean_: 
* _char_: fixed (`char` for state abbreviations) variable (`varchar` for freeform input) [Beaulieu 2.19]
* _numeric_: int (normal stuff) bigint (item number, GUID) float (precision) [Beaulieu 2.21] ğŸ—„ `math.md` encoding
* avoid non-floating point types unless stricty necessary https://www.sqlstyle.guide/#choosing-data-types
* avoid vendor-specific data types https://www.sqlstyle.guide/#choosing-data-types
* type conversion https://news.ycombinator.com/item?id=28259104
```sql
-- casting
select cast (avg(price) as integer) as "average sale price" from house;
-- timestamp https://pgexercises.com/questions/basic/date.html
YYYY-MM-DD HH:MM:SS  -- fmt
where foo_date > '1962-07-03' -- compare
-- user names
family_name, other_given_names  -- https://www.youtube.com/watch?v=458KmAKq0bQ 7:30 https://www.w3.org/International/questions/qa-personal-names
```

math
* integer division yields integer (`select 51/2` = `25`) ğŸ—„ FUQ - percent
* cast to float for precision division https://hakibenita.com/sql-dos-and-donts#be-careful-when-dividing-integers
* for decimals, multiply something by 1.0 (`select 1.0*51 / 2` = `25.5`)
* boolean: `0` falsy `1` truthy https://selectstarsql.com/beazley.html
```sh
select 0 or 1  # 1
```

# DML

execution order
* before execution, dbms checks query 1) perms 2) syntax ğŸ“™ Beaulieu 3.41
* only `select` is mandatory https://hakibenita.com/sql-for-data-analysis#basics
* types of execution order: syntactical/logical (e.g. no `where` after `having`) and actual (e.g. `limit` query engine will limit first) ğŸ“™ Bradshaw 166
* syntactical/logical order ğŸ“™ Evans 5, 14 https://jvns.ca/blog/2019/10/03/sql-queries-don-t-start-with-select/
```text
â”œâ”€â”€ from
â”œâ”€â”€ predicates
â”‚   â””â”€â”€ where
â”‚   â””â”€â”€ group by
â”‚   â””â”€â”€ having
â”œâ”€â”€ select
â”‚   â””â”€â”€ window functions ğŸ“™ Evans 14
â”‚   â””â”€â”€ order by ğŸ“™ Evans 13
â”‚   â””â”€â”€ limit
```

subqueries ğŸ“™ Beaulieu ch. 9
* _subquery_: query contained within another query ğŸ“™ Beaulieu 3.49
* _containing query_: query that wraps subquery ğŸ“™ Beaulieu 3.50
* _scalar subquery_: return single val from subquery https://learnsql.com/blog/subquery-vs-join/
* more readable but generally slower than joins https://stackoverflow.com/a/2577224
* more thinkable than joins https://stackoverflow.com/a/2577188
```sql
containing_query = (subquery)  -- 1 (scalar)
containing_query in (subquery)  -- n
```

## CRUD

```sql
-- 1 attr, 1 val
INSERT INTO danzi(customer) VALUES ('alice');
-- 1 attr, n val
INSERT INTO danzi(customer) VALUES ('alice'), ('bob');
-- n attr, 1 val
INSERT INTO danzi(customer, price) VALUES ('alice', 15)
-- n attr, n val
INSERT INTO danzi(customer, price) VALUES ('alice', 15), ('bob', 10);

UPDATE <tab> SET <col>=0 WHERE id=3;
DELETE FROM <tab> WHERE id=3;
```

## functions

* _function_: built-in function provided by dbms
* has return value https://stackoverflow.com/a/771959
* _trigger_: hook e.g. on record update write previous state to archive table ğŸ—„ `db.md` audit
* avoid data updates by tracking things from which current info can be derived i.e. DOB instead of age
```sql
--  https://github.com/jOOQ/sakila/blob/main/sqlite-sakila-db/sqlite-sakila-schema.sql
CREATE TRIGGER actor_trigger_ai AFTER INSERT ON actor
 BEGIN
  UPDATE actor SET last_update = DATETIME('NOW')  WHERE rowid = new.rowid;
 END
;
```

proc
* _procedure_: user-defined function
* no return value https://stackoverflow.com/a/771959
* aka stored procedure
* impl via procedural language availble in dbms
* too many and you've got business logic split btw application and db https://news.ycombinator.com/item?id=24845300

aggregate ğŸ“™ Beaulieu ch. 8
* _aggregate_: function that returns single val from result set https://www.postgresql.org/docs/12/tutorial-agg.html ğŸ—„ scalar
* operates on whole table or on group ğŸ“™ Beaulieu 8.149
* can't use in WHERE clause
* can't layer https://stackoverflow.com/a/2436957
```sql
-- count: ignores null https://hakibenita.com/sql-dos-and-donts#be-careful-when-counting-nullable-columns
select
    count(distinct addr) as "listings",
    cast (avg(price) as integer) as "avg",
    max(price) as "high",
    min(price) as "low"
from house
```

## grouping

ğŸ“™ Beaulieu ch. 8
ğŸ—„ `math.md` stat

group by
* _group by_: result set w/ 1 record for each group ğŸ“™ Evans 8, Beaulieu 5.54
* aka binning https://hakibenita.com/sql-for-data-analysis#binning
* aka pivot table https://hakibenita.com/sql-for-data-analysis#pivot-tables
```sql
-- only columns worth selecting are the grouped by column and aggregates
select count(*) from executions group by "First Name" 
select "First Name", count(*) from executions group by "First Name" 
select "First Name", count(*) from executions group by "First Name" order by 2 desc

-- can't usefully access non-aggregated columns
-- e.g. this query will bring back an execution age for one of the prisoners in the group, but what good is that?
select "Age at Execution" from executions group by "First Name" 
```
* ğŸ“ practice https://www.helenanderson.co.nz/sql-aggregate-functions/
* ğŸ“ rollup https://hakibenita.com/sql-for-data-analysis#subtotals

partition by
* _partition_: group by but retain individual records w/ group https://stackoverflow.com/a/2404574
* can do in DDL? https://www.postgresql.org/docs/10/ddl-partitioning.html#DDL-PARTITIONING-DECLARATIVE
* group created for aggregation ğŸ“™ Molinaro
* this tutorial is just ok https://www.youtube.com/watch?v=6trOvsL80Oo
* https://www.youtube.com/watch?v=EPUayNC5ku4

window functions ğŸ“™ Evans 14-16
* _window_: reference value in previous row ğŸ“™ Evans 14
* introduced to SQL in 2005 https://www.youtube.com/watch?v=H6OTMoXjNiM 0:30
```sql
-- syntax
expression OVER (window)
-- functions https://twitter.com/b0rk/status/1179419244808851462/photo/1
lag() sum() ntile() row_number()
```
* link to partition by https://twitter.com/b0rk/status/1179419244808851462/photo/1
* https://www.postgresql.org/docs/9.1/tutorial-window.html
* ğŸ“™ Winand 156
* https://www.youtube.com/watch?v=XBE09l-UYTE
* types https://www.helenanderson.co.nz/sql-window-functions-part-1/
* running total https://learnsql.com/blog/what-is-a-running-total-and-how-to-compute-it-in-sql/ https://learnsql.com/blog/sql-non-equi-joins-examples/
* https://hakibenita.com/sql-for-data-analysis#running-and-cumulative-aggregation

## operations

ğŸ—„ `language.md` semantics

relational ğŸ“™ Takahashi [43]
* _projection_: filter on attr i.e. `SELECT` https://stackoverflow.com/a/1031101 ğŸ“™ Takahashi [43] Beaulieu [44-5]
* _selection_: filter on value i.e. `WHERE` ğŸ“™ Beaulieu [52-54]
* _division_: extract records that exist in both numerator/denomenator table but only the columns that exist only in numerator ğŸ“™ Takahashi [45]
* + join

set ğŸ—„ `math.md` set theory ğŸ“™ Beaulieu ch. 6
* combine inputs to produce output [Takahashi 2.39]
* _cartesian product_: aka cross join [Beaulieu 5.83, Takahashi 2.42]
* except https://github.com/enochtangg/quick-SQL-cheatsheet#1-finding-data-queries
* https://github.com/enochtangg/quick-SQL-cheatsheet#find
```sql
-- DATA
-- customers: alice bob candace erin
-- employees: bob david frank

-- FMT
-- SELECT person FROM customer
-- <KEYWORD>
-- SELECT person FROM employee

UNION
-- el from both incl dupes https://stackoverflow.com/a/49928
-- alice, bob, bob, candace, david, erin, frank

UNION ALL
-- el from both minus dupes https://hakibenita.com/sql-dos-and-donts#know-the-difference-between-union-and-union-all
-- alice, bob, candace, david, erin, frank

INTERSECT
-- el shared [Beaulieu 6.100]
-- bob

MINUS
-- el unique to first set; aka difference [Bhargava 8.150]
-- alice, candace, erin
```

## predicates

* _predicate_: filter https://www.postgresql.org/docs/13/functions-comparison.html https://use-the-index-luke.com/sql/explain-plan/oracle/filter-predicates

where / having
* _where_: condition on individual records
* occurs before `group by` https://www.helenanderson.co.nz/sql-aggregate-functions/
* _having_: condition on group
* occurs after `group by` https://stackoverflow.com/a/9253267
```sql
-- comparison operator ğŸ“™ Beaulieu 4.63
where num >= 5

-- identity operator
where num is not null

-- membership; how subqueries work ğŸ“™ Beaulieu 4.71
where "name" in ('alice', 'bob');

-- range; is inclusive ğŸ“™ Beaulieu 4.70
where num between 3000 and 5000;
```

* FUQ
```sql
-- string truthy/falsy
select count(*) from executions where height != ''

-- percentage of attr w/ val https://stackoverflow.com/a/3919859
select
    (select count(height) from executions where height = '') * 100
    /
    (select count(height) from executions)
```

---

globbing
* not portable across DBMS [Karwin 15]
```sql
-- '%query%' = contained anywhere
-- https://github.com/enochtangg/quick-SQL-cheatsheet#1-finding-data-queries
select artists, genres from artist where genres like '%rock%'

LIKE 'foo%'; -- starts w/ 'foo'; '%' is n char [Beaulieu 4.74-5]
LIKE '%foo'; -- ends w/ 'foo'
LIKE '_foo'; -- has a single char before 'foo'
LIKE '%foo%'; -- contains anywhere https://pgexercises.com/questions/basic/where3.html

ILIKE 'Foo'; -- case sensitive
ILIKE 'foo'; -- case insensitive https://docs.djangoproject.com/en/3.1/ref/models/querysets/#iexact

where RIGHT(<col>, 3); -- ğŸ“ slice right: select subset of string ending with index n [Beaulieu 3.59]
where LEFT(<col>, 1) = 'T'; -- attr starts w/ 'T' -- left: select subset of string starting with index n [Beaulieu 4.73]
```

## select

distinct
* `DISTINCT`: dedupe
* slow for large result sets ğŸ“™ Beaulieu 3.48
* works on records, not columns https://discuss.codecademy.com/t/can-we-apply-distinct-to-a-select-query-with-multiple-columns/349723
```sql
--
-- DEDUPE W/ N COLUMNS
--

-- can't just use distinct bc works on records, not columns
-- i.e. result set valid bc each record different e.g. 5 rose st + house_id 1 != 5 rose st + house_id 3
select distinct house_id, addr from house
+----------+-----------------+
| house_id | addr            |
+----------+-----------------+
| 1        | 5 rose street   |
| 2        | 12 main street  |
| 3        | 5 rose street   |
+----------+-----------------+

-- the other approach here is using group by https://stackoverflow.com/a/12632129 ğŸ“™ Molinaro
select house_id, addr from house group by addr
+----------+-----------------+
| house_id | addr            |
+----------+-----------------+
| 2        | 12 main street  |
| 3        | 5 rose street   |
| 4        | 3 nice street   |
+----------+-----------------+


SELECT saleprice, saledate
FROM   sales
GROUP  BY saleprice, saledate
HAVING count(*) = 1 

SELECT MIN(id) FROM sales
GROUP BY saleprice, saledate
HAVING COUNT(id) = 1
```

aliases
* _alias_: shorthand for identifier
* need n aliases if using same table more than once ğŸ“™ Beaulieu 5.92
* `AS` not necessary but advisable ğŸ“™ Beaulieu 3.47, 3.52 https://www.sqlstyle.guide/#aliasing-or-correlations
```sql
select first_name || ' ' || last_name as full_name  -- column alias
    from people as p  -- table alias
    order by full_name  -- can be used in other commands

-- result set labelling
select count(addr) as "listings", max(price) as "high", min(price) as "low" from house
```

za
* syntax: select (attrs) from (tables) where (records) ğŸ“™ Molinaro 1.1
* _compound query_: combines multiple `SELECT` ğŸ“™ Beaulieu 103
* _scalar query_: query that returns single cell https://stackoverflow.com/a/20425116
* TOP: LIMIT for MySQL https://github.com/enochtangg/quick-SQL-cheatsheet#1-finding-data-queries ğŸ“™ Evans 13
* _ordinal notation_: refer to columns in select as ordinals https://stackoverflow.com/q/2253040
```sql
-- DESC: must be final clause
-- ASC: default, which is why you never see it ğŸ“™ Beaulieu 3.57
select "First Name", count(*) from executions group by "First Name" order by count(*) desc

-- concatenate https://pgexercises.com/questions/joins/threejoin.html
SELECT concat(mem.fname, ' ', mem.lname) as member  -- Postgre
SELECT mem.fname || ' ' || mem.lname as member  -- other dbms

-- case statements https://pgexercises.com/questions/basic/classify.html https://pgexercises.com/questions/joins/threejoin2.html
SELECT NAME,
	CASE
        WHEN (monthlymaintenance > 100)
        THEN 'expensive'
        ELSE 'cheap'
        END
    AS cost
FROM cd.facilities;  
```

# JOINS

ğŸ“™ Beaulieu ch. 5, 10

todo
* https://blog.codinghorror.com/a-visual-explanation-of-sql-joins/
* https://github.com/enochtangg/quick-SQL-cheatsheet#joins
* https://news.ycombinator.com/item?id=27760154
* https://alexpetralia.com/posts/2017/7/19/more-dangerous-subtleties-of-joins-in-sql

## basic

* _join_: include attr from n tables in result set ğŸ“™ Beaulieu 5.82
* for-loop combining records from diff tables based on condition
* _driving table_: starting point of join ğŸ“™ Beaulieu 5.90
```sql
-- no condition = cartesian result set (35)
from renter
join house
-- condition = non-cartesian (11)
from renter
join house
    on renter.district = house.district
```

* where / on / using
```sql
-- WHERE: old syntax
select * from employee, lob where employee.lob_id = lob.id

-- ON: new syntax (SQL92), portable across dbms ğŸ“™ Beaulieu 5.86-7
select * from employee, lob on employee.lob_id = lob.id

-- USING: use w/ equi join if tables have attr w/ same name ğŸ“™ Beaulieu 5.85 https://www.neilwithdata.com/join-using
select * from employee, lob using employee.lob_id = lob.lob_id
```

* 3 tables ğŸ“™ Beaulieu 5.88
```sql
-- basic
select deal.deal_id, house.addr, renter.`name`
from deal
    join house on deal.house = house.house_id
    join renter on deal.renter = renter.renter_id

-- w/ through table
select job_id, city
from job
    join job_geo on job.job_id = job_geo.job
    join geo on job_geo.geo = geo.geo_id
where job_id = 3
```

## I/O, L/R

* _inner_: result set doesn't include rows for which the join fails ğŸ“™ Beaulieu 5.83
* dbms defaults to inner ğŸ“™ Beaulieu 5.83-85
* most common type ğŸ“™ Evans 10
```sql
-- add to litecli.conf
select r.name, h.addr
from house as h
    join renter as r
    on r.district = h.district
```

* _outer_: result set does include rows for which join fails ğŸ“™ Beaulieu 5.84
```sql
-- pass
```

* _left_: left table determines count of result set ğŸ“™ Beaulieu 10.187
* right table provides match if found ğŸ“™ Evans 11-12
```sql
select r.name, d.deal_id
from renter as r
    join deal as d
    on r.renter_id = d.renter
+--------------+---------+
| name         | deal_id |
+--------------+---------+
| helen boss   | 1       |
| tom white    | 2       |
| sofia brown  | 3       |
| michael lane | 4       |
+--------------+---------+

select r.name, d.deal_id
from renter as r
    left join deal as d
    on r.renter_id = d.renter
+---------------+---------+
| name          | deal_id |
+---------------+---------+
| helen boss    | 1       |
| michael lane  | 4       |
| susan sanders | <null>  |
| tom white     | 2       |
| sofia brown   | 3       |
+---------------+---------+
```

* _right_: right table determines count of result set ğŸ“™ Beaulieu 10.187
```sql
select d.deal_id, r.renter
from renter as r
    right join deal as d
    on r.renter_id = d.renter
+---------------+---------+
| name          | deal_id |
+---------------+---------+
| helen boss    | 1       |
| michael lane  | 4       |
| susan sanders | <null>  |
| tom white     | 2       |
| sofia brown   | 3       |
+---------------+---------+
```

## self / equi

self, cross, natural, equi
* _self_: two instances of same table ğŸ“™ Beaulieu 5.93
```sql
-- pass
```

* _cross_: Cartesian product due to lack of `on` clause ğŸ“™ Beaulieu 5.83
```sql
select * from house join deal
```

* _natural_: don't specify `on` clause
* server figures out (which it will only do if there's matching attr name across tables) ğŸ“™ Beaulieu 10.198
* don't use!
```sql
-- pass
```

* _equi_: equality ğŸ“™ Beaulieu 5.94
```sql
-- pass
```

* _non-equi_: membership https://learnsql.com/blog/sql-non-equi-joins-examples/
```sql
-- trick for both of these is using a non-equi join to unmatch permutations ğŸ—„ `math.md` set theory
SELECT r1.name, r1.district, r2.name, r2.district
FROM renter as r1
    JOIN renter r2 ON r1.district = r2.district
    AND r1.renter_id < r2.renter_id

-- find dupes
select h1.house_id, h1.addr as "first occurence", h2.house_id, h2.addr as "second occurence"
from house as h1
    join house as h2 on h1.addr = h2.addr
    and h1.house_id < h2.house_id

-- recommendations
select r.name, h.house_id, h.district, h.addr, h.bedrooms, h.price
from renter as r
join house as h
    on r.district = h.district
    and h.price between r.rent_min and r.rent_max
    and r.bedrooms <= h.bedrooms
where h.house_id not in (select house from deal)
```

# MUNGE

ğŸ—„
* `math.md` stat
* `ml.md` data science / datasets
* `python.md` REPL
* `shell.md` munge

* _munge_: manipulate data outside db
* everything is data integration https://www.oreilly.com/radar/thinking-about-glue/
* aka derived data ğŸ“™ Kleppmann
* aka EDA
> When you get a fresh data set, the first thing you usually want to do is get familiar with it. Some people call this "Exploratory data analysis" [EDA]. https://hakibenita.com/sql-for-data-analysis#descriptive-statistics https://medium.com/epfl-extension-school/advanced-exploratory-data-analysis-eda-with-python-536fa83c578a

aggregate/analysis
* https://hakibenita.com/sql-for-data-analysis#descriptive-statistics
* https://hakibenita.com/sql-for-data-analysis#sampling
* reservoir sampling https://en.wikipedia.org/wiki/Reservoir_sampling https://github.com/BurntSushi/xsv
* stats https://github.com/capitalone/dataprofiler
* can use R from command line https://missing.csail.mit.edu/2020/data-wrangling/ https://www.r-project.org/

query ğŸ—„ `db.md` SQLite/CLI
* https://github.com/simonw/sqlite-utils
* https://github.com/harelba/q
* https://github.com/dinedal/textql
* https://github.com/multiprocessio/dsq
* diff https://github.com/datafold/data-diff

1) did not know Doordash/Google listings worked this way, feels both somewhat misleading but also entirely within their right (to the victor goes the spoils of customer intermediation)
2) I have actually never ordered delivery

editing panache
*Was this a bit shady? Maybe, but fuck Doordash. Note: I did confirm with my friend that he was okay with me writing this, and we both agreed, fuck Doordash.*

tricky, tricky
*Grubhub for their own sites generates a phone number for each restaurant that goes to a centralized, Grubhub owned call center. If someone calls in and orders via this number, the restaurant gets charged a fee. Apparently, some enterprising BD folks came up with the idea that Yelp could put the Grubhub phone numbers in place of the real restaurant phone number on the Yelp listing. Customers who think theyâ€™re â€œhelpingâ€ their local restaurants by calling in the order are still creating a fee for Grubhub.*

sanitization https://codex.wordpress.org/Validating_Sanitizing_and_Escaping_User_Data
* _validation_: compare against rules
* Pydantic https://www.pythonpodcast.com/pydantic-data-validation-episode-263/ https://github.com/shopnilsazal/validus https://blog.couchbase.com/validate-json-documents-in-python-using-pydantic/
* Cerberus https://github.com/pyeve/cerberus https://hector.dev/2020/12/29/validating-data-in-python-with-cerberus.html
* BYO https://realpython.com/primer-on-python-decorators/#more-real-world-examples https://blog.drewolson.org/declarative-validation
* _filter_: rm validation violations 
* _escape_: convert validation violations
* _sanitize_: validate + filter/escape
* _parameterize_: sanitization for SQL https://security.stackexchange.com/a/143925

## miller

ğŸ“œ
* https://miller.readthedocs.io/en/latest/glossary
* verbs https://miller.readthedocs.io/en/latest/reference-verbs/

* basics
```sh
# select *
cat <csv>

# limit
head -n 5 <csv>

# select col = -o -f col
cut -o -f "col1","col2" <csv>

# ignore col = -x -f co l
cut -x -f "col1","col2" <csv>

# chaining
head -n 20 then cut -o -f "id","artist" then sort -f "artist" <csv>
```

* predicates, grouping
```sh
# uniq for header
uniq -g <header> <csv> | wc -l

# select * where header = val
filter '$header == "value"' example.csv
filter '$header1 == "value-foo"' && '$header2 == "value-bar"' example.csv
filter 'is_null($header)' example.csv # https://miller.readthedocs.io/en/latest/reference-dsl-builtin-functions/
filter '$earnings > 0.0' example.csv

# most frequent value by header
most-frequent -f col -n 1000 example.csv

# most frequent value by header + group by header
most-frequent -f col -n 1000 example.csv | mlr --opprint sort -f col

# put = computed fields
# ${field} for fields w/ spaces
--c2p cut -o -f "21.08","21.09" then put '${total} = ${21.08} + ${21.09}' <csv>
```

* IO
```sh
--icsv    # input csv
--opprint # output pprint
--c2p     # combine --icsv and --opprint https://miller.readthedocs.io/en/latest/keystroke-savers/#short-format-specifiers-including-c2p
--csv     # IO csv
```

config https://miller.readthedocs.io/en/latest/customization/
* view colors: `--list-color-names` https://miller.readthedocs.io/en/latest/output-colorization/
* `.mlrrc`
```sh
c2p  # --c2p
allow-ragged-csv-input  # if data line fields > header line, insert empty val instead of err (CSV header/data length mismatch)
```

## Pandas

ğŸ“œ https://pandas.pydata.org/docs/
ğŸ“¹ https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS
ğŸ” 
* https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf
* https://github.com/jvns/pandas-cookbook
ğŸ“š
* McKinney https://wesmckinney.com/book/
* VanderPlas https://jakevdp.github.io/PythonDataScienceHandbook/

semantics
* _dataframe_: table https://www.youtube.com/watch?v=zmdjNSmRXF4 10:00
* _series_: 1d array https://pandas.pydata.org/docs/user_guide/10min.html#getting https://pandas.pydata.org/docs/user_guide/dsintro.html#series

* dataframes
```python
# load
import pandas as pd
df = pd.DataFrame(pd.read_csv("filename.csv"))

# iteration https://stackoverflow.com/questions/16476924/how-to-iterate-over-rows-in-a-dataframe-in-pandas https://stackoverflow.com/questions/50267185/iterate-over-pandas-series
for series in df.iterrows():

# predicate
df[df["company"] == "ABC corp"]  # equality
df[df["earnings"] > 0]  # comparison
df[(df["col1"] >= 1) & (df["col1"] <=1 )]  # uses indexing https://stackoverflow.com/a/13616382
```

* grouping
```python
# iteration ğŸ“™ McKinney [291]
for gk, grp in df.groupby("isrc"):
    pass

# csv per group https://stackoverflow.com/a/50818244
df = pd.DataFrame(pd.read_csv("paintings.csv"))
path = os.path.join(os.getcwd(), "output_dir")
for i, (name, group) in enumerate(df.groupby("ARTIST")):
    group.to_csv("{}/{}.csv".format(path, name.replace(" ", "").lower()))

# verify totals per group
invalid = list()
for _, (foo, group) in enumerate(df.groupby("foo")):
    if int(group["bar"].sum()) != 100:
        invalid.append(foo)
log.info("foo count - invalid: {}".format(len(invalid)))
```

snippets
```python
myl = [foo, bar]

# SHAPE https://stackoverflow.com/a/35523946
df.shape[0]  # count - rows
df.shape[1]  # count - col

# SELECT
df.col   # get col https://pandas.pydata.org/docs/user_guide/10min.html#getting
df[0:3]  # get row

# bool for each row
df.col.isin(myl)
# row index for True bool
df.index[df.col.isin(myl)]
# drop row indexes for rows matching list el
df.drop(df.index[df.col.isin(myl)])

# all col
df.columns
# n col
df[["col1", "col2"]]
# get row by row index
df.iloc[3]
# get row by row index + col index e.g. row 3 col 17
df.iloc[3, 17]
# get n row by row index e.g. rows 3 and 42
df.iloc[[3, 42]]

# persist foo w/ valid bar
verified = df.drop(df.index[df.foo.isin(invalid)])
log.info("count - verified: {}".format(len(set(verified.foo))))
verified.to_csv(os.path.join(os.getcwd(), out_file))
```

za
* method chaining https://github.com/pyjanitor-devs/pyjanitor
* validation https://github.com/pandera-dev/pandera
* perf https://hakibenita.com/sql-for-data-analysis#sql-vs-pandas-performance https://pythonspeed.com/memory
* test https://github.com/pandera-dev/pandera https://www.peterbaumgartner.com/blog/testing-for-data-science/
* version: 1.15 works w/ Python 3.6 https://pypi.org/project/numpy/#history ğŸ—„ `ml/grok-ml`

## spreadsheet

ğŸ—„ `python.md` REPL

strengths
* REPL for single table https://www.ultorg.com/

weaknesses
* n tables https://www.ultorg.com/
* UX for non-devs, hence Airtable https://luttig.substack.com/p/dont-forget-microsoft Airtable is bad? https://news.ycombinator.com/item?id=26448985 Airtable let's you attach images, documents https://github.com/nocodb/nocodb
* collaboration, hence Google Sheets https://luttig.substack.com/p/dont-forget-microsoft
* criticism https://betonit.substack.com/p/spreadsheets-letters-from-a-quant https://www.natemeyvis.com/writing/on-bryan-caplans-spreadsheets/

* _visicalc_: predecessor to Lotus123, Excel http://www.paulgraham.com/mac.html
* _UltOrg_: spreadsheet on top of dbms https://news.ycombinator.com/item?id=30868696 ğŸ” `Ultorg beta`
* ubiquity https://news.ycombinator.com/item?id=26386419 https://www.wsj.com/articles/stop-using-excel-finance-chiefs-tell-staffs-1511346601 https://news.ycombinator.com/item?id=28595155 https://dataingovernment.blog.gov.uk/2019/06/10/improving-how-we-manage-spreadsheet-data/ https://medium.com/backchannel/a-spreadsheet-way-of-knowledge-8de60af7146e
* praise https://www.reifyworks.com/writing/2017-01-25-i-was-wrong-about-spreadsheets-and-im-sorry
> Excel in my opinion is the most successful software application in history. https://subset.so/blog/excel-2-0 https://news.ycombinator.com/item?id=30868696
> Slightly overrated by users and wildly underrated by anyone who spends most of their time using more powerful tools https://diff.substack.com/p/inside-the-house-report-on-big-tech-6a6
> It blew my mind how many business critical processes were managed with excel spreadsheets being shared via email chains. It is incredible how flexible and effective Excel is for such a wide variety of use-cases. https://benadam.me/thoughts/my-experience-at-amazon/

Excel
* _workbook_: entire document
* _sheet_: sub-document
* can't open more than 1 million rows in single tab but can script so that Excel will break larger file into multiple tabs.
* row limit of 65k for xls files https://stackoverflow.com/a/45741831
* libraries https://www.xlwings.org/ https://realpython.com/openpyxl-excel-spreadsheets-python/ https://github.com/python-excel/xlrd https://github.com/dgorissen/pycel
* generate https://github.com/jazzband/tablib https://github.com/zachvalenta/csv-convert

## visidata

ğŸ” https://jsvine.github.io/visidata-cheat-sheet/en/
ğŸ“œ
* http://visidata.org/docs/
* https://jsvine.github.io/intro-to-visidata/

attr https://jsvine.github.io/intro-to-visidata/basics/understanding-columns/
* search: `/`
* nav: `hl`, `gh/gl`
* rename: `^`
* reorder: `H/L`
* create blank: `za` https://jsvine.github.io/intro-to-visidata/intermediate/creating-new-columns
* hide/remove: `-` / `gv`
* shrink by 1/2: `z-`
* expand json: `()`
* expand width to fit text: `_` (single) `g_` (all)

records
* mv: `SHIFT j/k`
* sort: `[]`
* page: `ctrl b/f`
* select: `s/u` (single) `gs/gu` (all)
* goto: `zr <num>`
> can use Vim https://www.youtube.com/watch?v=yhunJc8Nu4g
* edit: `e` https://jsvine.github.io/intro-to-visidata/basics/understanding-rows/#editing-row-cells
* edit w/ regex: `g*` https://www.youtube.com/watch?v=l2Bpmm0yAGw 4:24 https://www.visidata.org/docs/edit/
* save selected: `gY`

sheets
* _sheet_: god component https://jsvine.github.io/intro-to-visidata/basics/understanding-sheets/
* _meta sheet_: combo columns `C` sheets `S` summary `I`
* frequency `F` combo frequency `gF` https://jsvine.github.io/intro-to-visidata/basics/summarizing-data/#multi-column-frequencies
* pivot table https://jsvine.github.io/intro-to-visidata/intermediate/reshaping-data/#creating-pivot-tables
* _source sheet_: actual data
* _derived sheet_: derived data off source sheet
* reload/reset `ctrl r`
* toggle `ctrl 6`
* create from selected records `"` https://jsvine.github.io/intro-to-visidata/basics/sorting-and-filtering/#filtering-selected-rows-with
* save `ctrl s` https://www.youtube.com/watch?v=j0qn8OIiV-w 4:30
* exit: `q` single `gq` all `gs` view recently exited
* rm: `d`
* view deleted `gS`

za
* save cmdlog: `ctrl s`
* plugin for get duplicates https://jsvine.github.io/intro-to-visidata/advanced/extending-visidata/?highlight=duplicate
* pull values into new sheet https://www.youtube.com/watch?v=yhunJc8Nu4g 3:00
* pass cells to function https://www.youtube.com/watch?v=yhunJc8Nu4g 5:00

---

attr
* key: `!`; pins + certain cmd only apply to them https://jsvine.github.io/intro-to-visidata/basics/understanding-columns/#how-to-designate-key-columns
* aggregates: sum `z +` https://www.youtube.com/watch?v=yhunJc8Nu4g 4:20
* set type: `~` string `#` int `$` currency https://www.visidata.org/docs/graph/
* set value `g=` https://www.youtube.com/watch?v=yK3qgOIx4x0 3:20
> so even if underlying attr type is non-numeric can change type in sheet

misc
* create: sheet `A` attr `za` record `a` n records `ga` https://www.youtube.com/watch?v=yK3qgOIx4x0 0:25 1:30
* load data: `vd <file>` https://www.visidata.org/docs/loading/ https://www.visidata.org/formats/
* convert data: `vd <.json/csv> -b -o <name>.db` ğŸ—„ export sheet
* config: `shift o` global options sheet `z shift o` sheet-specific `~/.visidatrc` persistent https://jsvine.github.io/intro-to-visidata/advanced/configuring-visidata/
* cmd log: view `D` save `ctrl s` play `vd -p cmd_log.vd` https://www.youtube.com/watch?v=yK3qgOIx4x0 5:20 stored at `~/.visidata/history`
* help: `ctrl h` jumps to man page https://jsvine.github.io/intro-to-visidata/basics/getting-out-of-trouble/
* available cmds: `z ctrl h`
* graphing https://www.youtube.com/watch?v=Ozap_numsjI https://www.visidata.org/docs/graph/ https://www.youtube.com/watch?v=j0qn8OIiV-w
> check out deciles from aggregates
* munge delimited data https://www.youtube.com/watch?v=yhunJc8Nu4g
* _melt_: mv from 1 record n attr to n records 1 attr https://www.youtube.com/watch?v=yhunJc8Nu4g 2:30

* alternative https://github.com/TaKO8Ki/gobang
* rf using Paul's playlist https://www.youtube.com/playlist?list=PLxu7QdBkC7drrAGfYzatPGVHIpv4Et46W
https://www.youtube.com/playlist?list=PLxu7QdBkC7drrAGfYzatPGVHIpv4Et46W
* `:q` to exit vd itself vs. just quitting a sheet https://github.com/saulpw/visidata/issues/538 https://github.com/saulpw/visidata/issues/483 https://github.com/saulpw/visidata/issues/389 https://github.com/saulpw/visidata/issues/212
* connect to postgres https://www.visidata.org/formats/#postgres
* sort col `[` https://jsvine.github.io/intro-to-visidata/basics/sorting-and-filtering/#how-to-sort-rows
* filter col `| <filter>` https://jsvine.github.io/intro-to-visidata/basics/sorting-and-filtering/#filtering-selected-rows-with

attributes
* _go to_: â“ https://jsvine.github.io/intro-to-visidata/basics/navigating-visidata/#how-to-move-via-searching0
* _set type_: https://jsvine.github.io/intro-to-visidata/basics/understanding-columns/#how-to-set-column-types https://jsvine.github.io/intro-to-visidata/basics/understanding-columns/#manipulating-columns-from-the-columns-sheet

filter
* _joins_: https://jsvine.github.io/intro-to-visidata/intermediate/joining-sheets/
* _aggregation_: https://jsvine.github.io/intro-to-visidata/basics/summarizing-data/#adding-aggregators
* _aggregate on column_: https://jsvine.github.io/intro-to-visidata/basics/summarizing-data/#one-off-calculations

* load subset of file https://jsvine.github.io/intro-to-visidata/intermediate/large-files/#from-the-command-line
* select random subset https://jsvine.github.io/intro-to-visidata/intermediate/large-files/#select-a-random-sample-of-rows

* _select all records that match on current cell_: `| <val>` https://jsvine.github.io/intro-to-visidata/basics/understanding-rows/#by-matching-patterns
* _filter on selected_: `"` https://jsvine.github.io/intro-to-visidata/basics/sorting-and-filtering/#filtering-selected-rows-with https://jsvine.github.io/intro-to-visidata/basics/sorting-and-filtering/#using-frequency-tables-to-select-and-filter-for-multiple-values
* https://jsvine.github.io/intro-to-visidata/basics/navigating-visidata/#how-to-move-via-searching https://jsvine.github.io/intro-to-visidata/basics/understanding-rows/#via-expressions

## xsv

ğŸ“œ https://github.com/BurntSushi/xsv

```sh
# count records
count songs.csv

# get headers
headers songs.csv

# split into n files
split -s <records_per_file> <output-dir> <csv>

# all from header
select "header" <csv>

# search within header (case insensitive)
search -i -s "header" "query" <csv>

# stats (sum, min, max)
stats <table> | xsv table

# get sampled subset
xsv sample 50 full.csv > sample.csv
```

# PEDAGOGY

* tldr: better at SQL if data 1) local 2) interesting

## remote data

connect to actual server
* PG exercises https://github.com/zachvalenta/pg-exercises
* https://data.stackexchange.com/help
* https://sqlpd.com/
* https://news.ycombinator.com/item?id=30631477

baked data
* Datasette
* SQL.js https://selectstarsql.com/frontmatter.html#technicals https://github.com/sql-js/sql.js https://github.com/NUKnightLab/sql-mysteries
* https://dataschool.com/learn-sql/basic-practice/
* https://sql-playground.wizardzines.com/

## local data

sources
* general https://github.com/awesomedata/awesome-public-datasets https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks https://corgis-edu.github.io/corgis/csv/ https://www.data-is-plural.com/archive/
* JSON https://github.com/jdorfman/awesome-json-datasets
* csv https://github.com/secretGeek/awesomecsv#data
* ğŸ“ more in ğŸ—„ `ml.md`? put these there? Paul Swanson videos?
> put in ML

Postgres
* PG Exercises https://pgexercises.com/gettingstarted.html https://github.com/AlisdairO/pgexercises/issues/28

SQLite
* executions https://selectstarsql.com/frontmatter.html#dataset
* housing https://www.zillow.com/research/data/
* music https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks
* shootings https://catalog.data.gov/dataset/nypd-shooting-incident-data-historic
* verbos https://github.com/ghidinelli/fred-jehle-spanish-verbs

* HN https://github.com/dogsheep/hacker-news-to-sqlite https://news.ycombinator.com/submitted?id=luu
* movies https://simonwillison.net/2019/Feb/25/sqlite-utils/ https://github.com/jdorfman/awesome-json-datasets
* music https://corgis-edu.github.io/corgis/csv/music/ 

## dataclerk

ğŸ—„ `db.md` utils

* parse SQL https://news.ycombinator.com/item?id=32560039

---

* _personal data warehouse_: generated personal data https://simonwillison.net/2020/Nov/14/personal-data-warehouses/
* these always seem like a waste of time https://krausefx.com//blog/how-i-put-my-whole-life-into-a-single-database
* _personal database_: hand curated https://tomcritchlow.com/2022/01/26/electric-tables/ https://bofh.org.uk/2019/02/25/baking-with-emacs/

how to
* visidata?
* ERD?
* https://stackoverflow.com/questions/2732356/list-of-all-tables-with-a-relationship-to-a-given-table-or-view
* https://stackoverflow.com/questions/8094156/know-relationships-between-all-the-tables-of-database-in-sql-server

status quo
* user: web app
* admin: script/proc, visidata, GUI https://realpython.com/python-contact-book/#step-5-creating-new-contacts
* back office: ask admin, use Basedash https://softwareengineeringdaily.com/2020/10/12/basedash-low-code-database-editor-with-max-musing/ https://www.basedash.com/

# ZA

design
* SQL is boring and durable https://josephg.com/blog/databases-have-failed-the-web/
* SQL is outdated and awkward https://news.ycombinator.com/item?id=33034351
* ISO, ANSI standard [Beaulieu 5.86-7]
* case to replace SQL w/ something better https://www.scattered-thoughts.net/writing/against-sql
> The relational data model enables those things. None of them require the language to be SQL.
> LINQ, spark, flink, kafka streams, pandas, dataframes are all widely used examples of an expression-based language-embedded approach to relational queries.

za
* _object_: anything e.g. table, user, trigger https://docs.oracle.com/cd/B19306_01/server.102/b14200/sql_elements007.htm https://github.com/jOOQ/sakila/blob/ee1a637656aec2d82183ab451c56a3845315e761/mysql-sakila-db/mysql-sakila-drop-objects.sql
* _collation_: order in which char in character set are sorted ğŸ“™ Beaulieu 4.71
* _fuzzy matching_: merging n datasets that don't have a common UUID e.g. merging contacts based on name https://pbpython.com/record-linking.html
* _virtual column_: https://news.ycombinator.com/item?id=31396578

## commands

semantics ğŸ—„ `language.md` semantics
* _command_: keyword + identifier
* _keyword_: part of SQL lang spec; not case sensitive
* _identifier_: value (cell, attribute); case-sensitive
* quotes: single for value, double for attr https://stackoverflow.com/q/1992314
```sql
SELECT "from" FROM foo WHERE something = 'val';
```
* _query_: `SELECT` command ğŸ“™ Karwin 6
* _statement_: non-`SELECT` commands ğŸ“™ Karwin 6

command types
* _DCL_: control; user perms https://stackoverflow.com/a/44898661
* _DDL_: definition; table structure and inter-table relationships https://stackoverflow.com/a/2578207
* _DML_: manipulation; CRUD

keyword types https://www.postgresql.org/docs/8.1/sql-keywords-appendix.html https://www.sqlstyle.guide/#reserved-keyword-reference
* _keyword_: reserved + non-reserved
* case-insensitive
* _reserved_: word that cannot use as identifier e.g. `create`
* _non-reserved_: word that you can use as identifier but should use backtickets for e.g. `assertion`, `name`
> As a general rule, if you get spurious parser errors for commands that contain any of the listed key words as an identifier you should try to quote the identifier to see if the problem goes away. - https://www.postgresql.org/docs/8.1/static/sql-keywords-appendix.html

## DCL

* _get current user_: `select current_user;` or `select user();`
* _create user_: `CREATE USER alice WITH PASSWORD '1234';` `CREATE USER '<name>'@'localhost';
* scope reads to currrent user https://news.ycombinator.com/item?id=23308945

* give user perms to db
```sql
GRANT ALL PRIVILEGES ON <dbName>.* to '<userName>'@'localhost' WITH GRANT OPTION; 
FLUSH PRIVILEGES;
```

* test user privileges
```sql
mysql -u user_name
USE db_name;
CREATE TABLE test_table (c CHAR(20));
INSERT INTO test_table(name, age) values('zach', 31);
SELECT * FROM test_table;
DROP TABLE test_table;
```

## ORM

ğŸ—„ `django.md` db

----

* reverse query builder https://www.thoughtworks.com/radar/languages-and-frameworks?blipid=202203030 https://github.com/kyleconroy/sqlc

impl
* _data mapper_: https://en.wikipedia.org/wiki/SQLAlchemy https://www.openmymind.net/2011/11/18/I-Just-Dont-Like-Object-Mappers/
* _active record_: wrapper (row + DSL) https://www.martinfowler.com/eaaCatalog/activeRecord.html http://calpaterson.com/activerecord.html

query builders
* _query builder_: what it sounds like; cares about physical tables, doesn't care about objects (not an ORM)
* Pypika https://github.com/kayak/pypika https://github.com/zachvalenta/query-sandbox/blob/main/queries.py
* aiosql https://github.com/nackjicholson/aiosql
* csql https://news.ycombinator.com/item?id=24866377
* BYO https://death.andgravity.com/query-builder-how
* spyql https://github.com/dcmoura/spyql https://news.ycombinator.com/item?id=30074787

---

* learn SQL https://sirupsen.com/stop-relying-on-your-orm-and-learn-sql
* async https://github.com/tortoise/tortoise-orm
* generate ORM from DDL https://github.com/volatiletech/sqlboiler
* _impedance mismatch_: difficulty of object-relational mapping [Kleppmann 1.33] multiple ways to aproach http://blogs.tedneward.com/post/the-vietnam-of-computer-science/

ORMS in general
* _ORM(object-relational mapping)_: obj as frontend to relational data store
* an ORM is a feature for the app framework, not your app i.e. you probably won't have to switch between dbms https://news.ycombinator.com/item?id=24074520
* _ä¼˜ç‚¹_: dbms portability, terseness https://monadical.com/posts/why-use-orm.html
* _ç¼ºç‚¹_: SQL's durability https://news.ycombinator.com/item?id=21961214 more SO help on SQL, complicate relations https://eli.thegreenplace.net/2019/to-orm-or-not-to-orm/
* write thin DSL over ORM vs. modifying default ORM methods https://rtpg.co/2016/09/12/orms-are-scary.html
* _N+1 problem_: https://macwright.org/2020/05/10/spa-fatigue.html https://stackoverflow.com/q/97197/6813490 https://www.sqlalchemy.org/features.html https://tech.yplanapp.com/2016/09/26/introducing-django-perf-rec/ https://www.youtube.com/watch?v=uCbFMZYQbxE https://github.com/jmcarp/nplusone https://news.ycombinator.com/item?id=26151302 https://fly.io/blog/introducing-litefs/
* solved with eager loading https://news.learnenough.com/eager-loading

not SQLAlchemy
* _aiosql_: load sql file into Python and run queries as methods https://github.com/nackjicholson/aiosql
* _dataset_: use db like csv file https://dataset.readthedocs.io/en/latest/index.html 
* _orator_: from the guy who did Poetry https://github.com/sdispater/orator
* _records_: anyone use this? https://github.com/kennethreitz/records
* _Peewee_: not for async https://fastapi.tiangolo.com/advanced/sql-databases-peewee/ https://github.com/coleifer/peewee 
* _SQLmodel_: SQLAlchemy wrapper https://github.com/tiangolo/sqlmodel

SQLAlchemy http://aosabook.org/en/sqlalchemy.html https://docs.sqlalchemy.org/en/13/ https://www.sqlalchemy.org/library.html#tutorials
* https://talkpython.fm/episodes/show/344/sqlalchemy-2.0
* https://realpython.com/python-sqlite-sqlalchemy/
* tutorial https://www.youtube.com/watch?v=5SSC6nU314c
* create table `create_all` https://docs.sqlalchemy.org/en/14/core/metadata.html#creating-and-dropping-database-tables
* _core_: manages connection pool and dialects (diff dbms); fine to just use core https://news.ycombinator.com/item?id=10270605
* _JSONField_: https://amercader.net/blog/beware-of-json-fields-in-sqlalchemy/
* _core - components_: engine, connection, session https://stackoverflow.com/a/42772654/6813490 event system https://www.sqlalchemy.org/features.html
* _ORM_: niceties on top of core https://www.sqlalchemy.org/features.html
* _row object_: record https://stackoverflow.com/q/1958219
* _unit of work_: writes changes all at once, similar to how Hibernate does it https://www.sqlalchemy.org/features.html
* build queries from functions https://www.sqlalchemy.org/features.html
* built on PEP249 (DBAPI) https://www.python.org/dev/peps/pep-0249/
* _not async_: even if your app framework if
* `bulk_save_objects` doesn't seem to work when it comes to backrefs https://github.com/zachvalenta/flask-skeleton/commit/548c36088dfe595fccabeb67fa11c7254e847948#diff-c61c1bc5b0486cc6e721bee29c28fe33R17
* search expressions w/ engine https://stackoverflow.com/questions/3325467/sqlalchemy-equivalent-to-sql-like-statement
* _parameterized query_: `select foo from bar where baz = :bazid` https://docs.sqlalchemy.org/en/13/core/tutorial.html#using-textual-sql https://stackoverflow.com/a/18808942/6813490 apparently should use a session https://stackoverflow.com/a/22084672/6813490
* compared to Django https://apirobot.me/posts/introduction-to-sqlalchemy-orm-for-django-developers
* sessions
> This is not at all how SQLAlchemy's ORM component works. In SQLAlchemy you have an object called the â€œsessionâ€. It basically encapsulates a transaction. However it does more. Each object is tracked by primary key in this session. As such each object only exists once by primary key. As such you can safely make a lot of queries and you never have things out of sync. When you commit the session it will send all changes at once to the database in correct order, if you rollback the session nothing happens instead. - http://lucumr.pocoo.org/2011/7/19/sqlachemy-and-you/

* _backref_: used for 1-M, adds virtual column to obj from parent table that enforces constraint on child table itself https://flask-sqlalchemy.palletsprojects.com/en/2.x/models/?highlight=backref https://docs.sqlalchemy.org/en/13/orm/backref.html#linking-relationships-with-backref
```python
# PARENT
class Concert(db.Model):
    concert_id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.Text)
    performances = db.relationship("Performance", backref="concert")

# backref = no change to underlying table
+-----+------------+---------+---------+------------+----+
| cid | name       | type    | notnull | dflt_value | pk |
+-----+------------+---------+---------+------------+----+
| 0   | concert_id | INTEGER | 1       | <null>     | 1  |
| 1   | name       | TEXT    | 0       | <null>     | 0  |
+-----+------------+---------+---------+------------+----+

# rather, gets virtual column i.e. query run on obj creation to fetch all child obj that reference parent https://www.youtube.com/watch?v=cYWiDiIUxQc 15:20
Concert.query.get(1).performances

# CHILD
class Performance(db.Model):
    perf_id = db.Column(db.Integer, primary_key=True)
    concert_id = db.Column(db.Integer, db.ForeignKey("concert.concert_id"))

# FK = adds constraint via column on underlying table
+-----+------------+---------+---------+------------+----+
| cid | name       | type    | notnull | dflt_value | pk |
+-----+------------+---------+---------+------------+----+
| 0   | perf_id    | INTEGER | 1       | <null>     | 1  |
| 1   | concert_id | INTEGER | 0       | <null>     | 0  |
+-----+------------+---------+---------+------------+----+
# physical column reflected in ORM obj
Performance.query.get(1).concert_id  # 1
# but also gets virtual column as well
Performance.query.get(1).concert  # id 1 name Glastonbury
```

* snippets
```python
###
# JOINS https://stackoverflow.com/q/19841877/6813490 https://stackoverflow.com/q/6044309/6813490
###

outer = (
    db.session.query(Artist, Song)
    .outerjoin(Song, Artist.artist_id == Song.artist_id)
    .all()
)
outer_pages = (
    db.session.query(Artist, Song)
    .outerjoin(Song, Artist.artist_id == Song.artist_id)
    .paginate()
)

inner = (
    db.session.query(Artist, Song).join(Song, Artist.artist_id == Song.artist_id).all()
)

# pull values out of result set obj https://stackoverflow.com/a/42093713/6813490
# irl you'd want to use Marshmallow for this
class Artist(db.Model):
    artist_id = db.Column(db.Integer, primary_key=True)

class Song(db.Model):
    song_id = db.Column(db.Integer, primary_key=True)
    artist_id = db.Column(db.Integer, db.ForeignKey('artist.artist_id'), nullable=False)

artists = [Artist(artist_name='Massive Attack'), Artist(artist_name='Nas')]
songs = [Song(song_name='One Love', artist_id=2), Song(song_name='One Love', artist_id=1)]

query = "select artist_name, song_name from song s inner join artist a on s.artist_id = a.artist_id where artist_name='Massive Attack'"
for x in db.engine.execute(query):
    print(x)  # ('Massive Attack', 'One Love')

@app.route("api")
def get_foo():
    query = "select col1, col2 from foo"
    rs = db.engine.execute(query).fetchall()
    marshalled_rs = [x[0, 1] for x in rs]
    return jsonify({"results": marshalled_rs})

# saving from repl https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-iv-database 'shell'
# unable to persist a record using Flask-SQLAlchemy from the Python REPL, but the same code works fine when run as a script.

# APP.PY

import os
from dotenv import find_dotenv, load_dotenv
from flask import Flask
from flask_sqlalchemy import SQLAlchemy

load_dotenv(find_dotenv())
basedir = os.path.abspath(os.path.dirname(__file__))
db_path = os.path.join(basedir, os.getenv("DATABASE"))
db_uri = "sqlite:///" + db_path

app = Flask(__name__)
app.config["SQLALCHEMY_TRACK_MODIFICATIONS"] = False
app.config["SQLALCHEMY_DATABASE_URI"] = db_uri
db = SQLAlchemy(app)

class Thing(db.Model):
    thing_id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(30))
    description = db.Column(db.Text)

    def __repr__(self):
        return f"id {self.thing_id} name {self.name} desc {self.description}"
    
# DB_SEED.PY

#!/usr/bin/env python
from app import db, Thing

db.drop_all()
db.create_all()
thing = Thing(name="thing1", description="thing-1-desc")
db.session.add(thing)
db.session.commit()
print(f"new thing {Thing.query.all()} \n")
```
```sh
# Running the script persists a record
$ poetry run python db_seed.py
new thing [id 1 name thing1 desc thing-1-desc]
# When I try to do the same thing from inside the Python REPL, however, the record isn't created
>>> from app import db, Thing
>>> db.drop_all()
>>> db.create_all()
>>> thing = Thing(name="thing1", description="thing-1-desc")
>>> db.session.add(thing)
>>> db.session.commit()
>>> Thing.query.all()
[]
```

## style

ğŸ“œ style https://www.sqlstyle.guide/

misc
* âœ… constraints next to the attr they constrain https://www.sqlstyle.guide/#layout-and-order
* âœ… suffixes https://www.sqlstyle.guide/#uniform-suffixes
* âœ… uppercase keywords https://www.sqlstyle.guide/#reserved-words
* indentation along root keywords (select, from, where) https://www.sqlstyle.guide/#indentation https://www.sqlstyle.guide/#spaces
* white space / tabs not significant

naming
* âœ… ubiquitous language âŒ but no Hungarian notation https://news.ycombinator.com/item?id=24403236 
* âœ… starts w/ char, use underscores where you'd use a space in natural language https://www.sqlstyle.guide/#naming-conventions
* âŒ Hungarian notation https://www.sqlstyle.guide/#tables https://news.ycombinator.com/item?id=24403236
* âŒ through table as concatentation of its constituents https://www.sqlstyle.guide/#tables
* âŒ `id` as PK https://www.sqlstyle.guide/#columns https://github.com/jOOQ/jOOQ/tree/master/jOOQ-examples/Sakila
* âœ… singular for attr https://www.sqlstyle.guide/#columns

## tables

types
* _table_: set of related rows
* _permanent table_: table in storage ğŸ“™ Beaulieu 3.49 impl as heap or b-tree https://calpaterson.com/activerecord.html
* _temporary table_: table in mem ğŸ“™ Beaulieu 3.49
* aka non-persistent ğŸ“™ Beaulieu 1.7
* same as intermediate table? https://hakibenita.com/sql-tricks-application-dba#implement-complete-processes-using-with-and-returning
* _scalar table_: table w/ single column and single row https://pgexercises.com/questions/basic/agg2.html
* _temporal_: https://news.ycombinator.com/item?id=29733854 https://news.ycombinator.com/item?id=29735695 https://stackoverflow.com/questions/50199752/comparing-csv-entries-against-entries-in-postgresql-table-using-python 

result set
* _result set_: return from a query
* type of temp table ğŸ“™ Beaulieu 3.42, Evans 4
* intermediate rs created at each stage in join ğŸ“™ Beaulieu 5.90

components ğŸ“™ Beaulieu 1.6
* _entity_: thing you're trying to describe e.g. customer, order, et al. [Beaulieu 1.6]
* _attribute_: aka column
* _record_: aka row
* _value_: aka cell, field

views ğŸ“™ Beaulieu chapter 14
* _view_: pre-computed partial query (e.g. `where is_active = 0`) recomputed as more full query w/ additional user filtering ğŸ“™ Kleppmann 101
* doesn't hold any data itself ğŸ“™ Beaulieu 3.50
* restrict users to subset of data https://stackoverflow.com/a/4378291/6813490
* simplifies queries for users but lose info about relationships ğŸ“™ Beaulieu 3.51 https://dataschool.com/sql-optimization/views/
* for some dbms (SQLite) you can't write using views https://sqlite.org/omitted.html
* _materialized view_: actual data i.e. cached version of the table; faster queries but needs to be manually maintained so not typically used in OLTP [Kleppmann 102]
* _data cube_: type of materialized view used in OLAP, precomputed for speed results ğŸ“™ Kleppmann 102 https://hakibenita.com/sql-for-data-analysis#cube
* not often used limited query flexiblity ğŸ“™ Kleppmann 103

CTE
* _CTE (common table expression)_: one-off view
```sql
with  -- https://github.com/enochtangg/quick-SQL-cheatsheet#find https://hakibenita.com/sql-tricks-application-dba#implement-complete-processes-using-with-and-returning
```
* recursion http://www.jeffwidman.com/blog/ https://dba.stackexchange.com/q/14490 https://medium.com/swlh/recursion-in-sql-explained-graphically-679f6a0f143b https://aiven.io/blog/solving-the-knapsack-problem-in-postgresql https://pgexercises.com/questions/recursive/ https://bofh.org.uk/2019/02/25/baking-with-emacs/
* https://github.com/enochtangg/quick-SQL-cheatsheet#find
* https://hakibenita.com/sql-for-data-analysis#common-table-expressions https://hakibenita.com/sql-for-data-analysis#sql-vs-pandas-performance 
